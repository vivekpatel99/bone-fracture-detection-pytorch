{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bone Fracture Detection using YOLOv8\n",
    "\n",
    "This Jupyter Notebook explores the application of deep learning for bone fracture detection using a comprehensive X-ray image dataset.  The dataset is specifically designed for computer vision projects and aims to facilitate the development and evaluation of automated bone fracture detection algorithms.\n",
    "\n",
    "## About the Dataset\n",
    "\n",
    "The dataset encompasses X-ray images categorized into several classes, each representing a specific type of bone fracture within the upper extremities. These classes include:\n",
    "\n",
    "*   Elbow Positive\n",
    "*   Fingers Positive\n",
    "*   Forearm Fracture\n",
    "*   Humerus Fracture\n",
    "*   Shoulder Fracture\n",
    "*   Wrist Positive\n",
    "\n",
    "Each image is annotated with either bounding boxes or pixel-level segmentation masks, precisely indicating the location and extent of the detected fracture. These annotations are crucial for training and evaluating bone fracture detection algorithms, particularly object detection models.\n",
    "\n",
    "This dataset provides a valuable resource for researchers and developers working on automated fracture detection. Its diverse range of fracture classes enables the training of robust models capable of accurately identifying fractures in various regions of the upper extremities. The ultimate goal of this dataset is to accelerate the development of computer vision solutions for automated fracture detection, thereby contributing to advancements in medical diagnostics and improved patient care.\n",
    "\n",
    "**When using this dataset for your research, please cite it using the following DOI:** 10.13140/RG.2.2.14400.34569\n",
    "\n",
    "**You can also find the dataset on ResearchGate:** [https://www.researchgate.net/publication/382268240_Bone_Fracture_Detection_Computer_Vision_Project](https://www.researchgate.net/publication/382268240_Bone_Fracture_Detection_Computer_Vision_Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')], '2.18.0')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "\n",
    "tf.config.list_physical_devices('GPU'), tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading kaggle keys\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/BoneFractureYolo8/train/\n"
     ]
    }
   ],
   "source": [
    "from hydra import initialize, compose\n",
    "\n",
    "# https://gist.github.com/bdsaglam/586704a98336a0cf0a65a6e7c247d248\n",
    "\n",
    "with initialize(version_base=None, config_path=\"conf\"):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    print(cfg.DATASET_DIRS.TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'elbow positive',\n",
       " 1: 'fingers positive',\n",
       " 2: 'forearm fracture',\n",
       " 3: 'humerus fracture',\n",
       " 4: 'humerus',\n",
       " 5: 'shoulder fracture',\n",
       " 6: 'wrist positive'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES = ['elbow positive',\n",
    "               'fingers positive',\n",
    "               'forearm fracture',\n",
    "               'humerus fracture',\n",
    "               'humerus',\n",
    "               'shoulder fracture',\n",
    "               'wrist positive']\n",
    "\n",
    "class_mapping = dict(zip(range(len(CLASS_NAMES)), CLASS_NAMES))\n",
    "class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = cfg.DATASET_DIRS.TRAIN_DIR\n",
    "VALIDATION_DIR = cfg.DATASET_DIRS.VALIDATION_DIR\n",
    "TEST_DIR = cfg.DATASET_DIRS.TEST_DIR\n",
    "\n",
    "TRAIN_IMAGE_DIR = f'{TRAIN_DIR}/images'\n",
    "TRAIN_LABELS_DIR = f'{TRAIN_DIR}/labels'\n",
    "\n",
    "VALID_IMAGE_DIR = f'{VALIDATION_DIR}/images'\n",
    "VALID_LABELS_DIR = f'{VALIDATION_DIR}/labels'\n",
    "\n",
    "TEST_IMAGE = f'{TEST_DIR}/images'\n",
    "TEST_LABELS = f'{TEST_DIR}/labels'\n",
    "\n",
    "IMG_SIZE = cfg.TRAIN.IMG_SIZE\n",
    "BATCH_SIZE = cfg.TRAIN.BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TRAIN_IMAGE_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprepare_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PrepareDataset\n\u001b[0;32m----> 4\u001b[0m preparer_train_ds \u001b[38;5;241m=\u001b[39m PrepareDataset(image_dir\u001b[38;5;241m=\u001b[39m\u001b[43mTRAIN_IMAGE_DIR\u001b[49m,\n\u001b[1;32m      5\u001b[0m                                    label_dir\u001b[38;5;241m=\u001b[39mTRAIN_LABELS_DIR)\n\u001b[1;32m      6\u001b[0m image_paths, labels, bboxes \u001b[38;5;241m=\u001b[39m preparer_train_ds\u001b[38;5;241m.\u001b[39mget_dataset()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mlen\u001b[39m(image_paths), \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(bboxes)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TRAIN_IMAGE_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "from utils.prepare_dataset import PrepareDataset\n",
    "\n",
    "\n",
    "preparer_train_ds = PrepareDataset(image_dir=TRAIN_IMAGE_DIR,\n",
    "                                   label_dir=TRAIN_LABELS_DIR)\n",
    "image_paths, labels, bboxes = preparer_train_ds.get_dataset()\n",
    "len(image_paths), len(labels), len(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_tensor = tf.ragged.constant(bboxes)\n",
    "classes_tensor = tf.ragged.constant(labels)\n",
    "image_paths_tensor = tf.ragged.constant(image_paths)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (image_paths_tensor, classes_tensor, bboxes_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_datasets = PrepareDataset(image_dir=VALID_IMAGE_DIR,\n",
    "#                                 label_dir=VALID_LABELS_DIR)\n",
    "\n",
    "# valid_ds = tf.data.Dataset.from_tensor_slices((tf.ragged.constant(image_paths),\n",
    "#                                                tf.ragged.constant(labels),\n",
    "#                                                tf.ragged.constant(bboxes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    print(image.shape)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_dataset(image_path, classes, bbox):\n",
    "    # Read Image\n",
    "    image = load_image(image_path)\n",
    "    bounding_boxes = {\n",
    "        \"classes\": tf.cast(classes, dtype=tf.float32),\n",
    "        \"boxes\": bbox,\n",
    "    }\n",
    "    return {\"images\": tf.cast(image, tf.float32), \"bounding_boxes\": bounding_boxes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 3)\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.shuffle(BATCH_SIZE * 4)\n",
    "train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512, None, 3])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = next(iter(train_ds.take(1)))\n",
    "images, bounding_boxes = inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "image = images[0].numpy()\n",
    "images[0].get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
