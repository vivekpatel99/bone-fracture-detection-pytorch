{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung and Colon Cancer Classification\n",
    "## About Dataset\n",
    "This dataset contains 25,000 histopathological images with 5 classes. All images are 768 x 768 pixels in size and are in jpeg file format.\n",
    "The images were generated from an original sample of HIPAA compliant and validated sources, consisting of 750 total images of lung tissue (250 benign lung tissue, 250 lung adenocarcinomas, and 250 lung squamous cell carcinomas) and 500 total images of colon tissue (250 benign colon tissue and 250 colon adenocarcinomas) and augmented to 25,000 using the Augmentor package.\n",
    "There are five classes in the dataset, each with 5,000 images, being:\n",
    "\n",
    "* Lung benign tissue\n",
    "* Lung adenocarcinoma\n",
    "* Lung squamous cell carcinoma\n",
    "* Colon adenocarcinoma\n",
    "* Colon benign tissue\n",
    "\n",
    "\n",
    "How to Cite this Dataset\n",
    "If you use in your research, please credit the author of the dataset:\n",
    "\n",
    "Original Article\n",
    "Borkowski AA, Bui MM, Thomas LB, Wilson CP, DeLand LA, Mastorides SM. Lung and Colon Cancer Histopathological Image Dataset (LC25000). arXiv:1912.12142v1 [eess.IV], 2019\n",
    "\n",
    "Relevant Links\n",
    "https://arxiv.org/abs/1912.12142v1\n",
    "https://github.com/tampapath/lung_colon_image_set\n",
    "Dataset BibTeX\n",
    "@article{,\n",
    "title= {LC25000 Lung and colon histopathological image dataset},\n",
    "keywords= {cancer,histopathology},\n",
    "author= {Andrew A. Borkowski, Marilyn M. Bui, L. Brannon Thomas, Catherine P. Wilson, Lauren A. DeLand, Stephen M. Mastorides},\n",
    "url= {https://github.com/tampapath/lung_colon_image_set}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import hydra\n",
    "import lightning as pl\n",
    "import numpy as np\n",
    "import opendatasets as od\n",
    "import optuna\n",
    "import pyrootutils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "root = pyrootutils.setup_root(\n",
    "    search_from=os.path.dirname(os.getcwd()),\n",
    "    indicator=[\".git\", \"pyproject.toml\"],\n",
    "    pythonpath=True,\n",
    "    dotenv=True,\n",
    ")\n",
    "\n",
    "if os.getenv(\"DATA_ROOT\") is None:\n",
    "    os.environ[\"DATA_ROOT\"] = f\"{root}\"\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Register a resolver for torch dtypes\n",
    "OmegaConf.register_new_resolver(\"torch_dtype\", lambda name: getattr(torch, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/processed/train\n"
     ]
    }
   ],
   "source": [
    "# https://gist.github.com/bdsaglam/586704a98336a0cf0a65a6e7c247d248\n",
    "\n",
    "with initialize(version_base=\"1.2\", config_path=\"../configs\"):\n",
    "    cfg = compose(config_name=\"train\")\n",
    "    print(cfg.paths.train_processed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = Path(root) / cfg.data.dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR.mkdir(exist_ok=True)\n",
    "if len(list(DATASET_DIR.iterdir())) == 0:\n",
    "    # Download the dataset\n",
    "    od.download(dataset_id_or_url=cfg.data.dataset_url, data_dir=str(DATASET_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'colon-adenocarcinoma',\n",
       " 1: 'colon-benign-tissue',\n",
       " 2: 'lung-adenocarcinoma',\n",
       " 3: 'lung-benign-tissue',\n",
       " 4: 'lung-squamous-cell-carcinoma'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES = [\n",
    "    \"colon-adenocarcinoma\",\n",
    "    \"colon-benign-tissue\",\n",
    "    \"lung-adenocarcinoma\",\n",
    "    \"lung-benign-tissue\",\n",
    "    \"lung-squamous-cell-carcinoma\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungColonDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_processed_dir: str,\n",
    "        valid_processed_dir: str,\n",
    "        test_processed_dir: str,\n",
    "        augmentations: Any,\n",
    "        valid_transforms: Any,\n",
    "        num_workers: int = 8,\n",
    "        pin_memory: bool = True,\n",
    "        persistent_workers: bool = True,\n",
    "        batch_size: int = 32,\n",
    "        subset_size: float | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_data_dir = train_processed_dir\n",
    "        self.valid_data_dir = valid_processed_dir\n",
    "        self.test_data_dir = test_processed_dir\n",
    "        self.augmentations = None\n",
    "        self.valid_transforms = None\n",
    "        self.subset_size = subset_size\n",
    "        if augmentations:\n",
    "            aug = hydra.utils.instantiate(augmentations)\n",
    "            self.augmentations = v2.Compose(aug)\n",
    "        if valid_transforms:\n",
    "            transforms = hydra.utils.instantiate(valid_transforms)\n",
    "            self.valid_transforms = v2.Compose(transforms)\n",
    "\n",
    "        self.kwargs = {\n",
    "            \"batch_size\": batch_size,\n",
    "            \"num_workers\": num_workers,\n",
    "            \"pin_memory\": pin_memory,\n",
    "            \"persistent_workers\": persistent_workers,\n",
    "        }\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def subset_indices(self, dataset, subset_size):\n",
    "        train_ds_len = len(dataset)\n",
    "        indices = np.arange(len(dataset))[: int(train_ds_len * self.subset_size)]\n",
    "        return indices\n",
    "\n",
    "    def setup(self, stage=None) -> None:\n",
    "        # Set up the dataset for training and validation\n",
    "        self.train_dataset = ImageFolder(root=self.train_data_dir, transform=self.augmentations)\n",
    "        self.val_dataset = ImageFolder(root=self.valid_data_dir, transform=self.valid_transforms)\n",
    "        self.test_dataset = ImageFolder(root=self.test_data_dir, transform=self.valid_transforms)\n",
    "\n",
    "        if self.subset_size:\n",
    "            print(f\"Using subset of size {self.subset_size} for training, validation, and testing.\")\n",
    "            # Subset the dataset\n",
    "            train_indices = self.subset_indices(self.train_dataset, self.subset_size)\n",
    "            self.train_dataset = torch.utils.data.Subset(self.train_dataset, train_indices)\n",
    "            val_indices = self.subset_indices(self.val_dataset, self.subset_size)\n",
    "            self.val_dataset = torch.utils.data.Subset(self.val_dataset, val_indices)\n",
    "            test_indices = self.subset_indices(self.test_dataset, self.subset_size)\n",
    "            self.test_dataset = torch.utils.data.Subset(self.test_dataset, test_indices)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            shuffle=True,\n",
    "            **self.kwargs,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            **self.kwargs,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            **self.kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using subset of size 0.1 for training, validation, and testing.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1800, 450, 250)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = LungColonDataModule(\n",
    "    train_processed_dir=str(Path(root) / cfg.paths.train_processed_dir),\n",
    "    valid_processed_dir=str(Path(root) / cfg.paths.valid_processed_dir),\n",
    "    test_processed_dir=str(Path(root) / cfg.paths.test_processed_dir),\n",
    "    augmentations=cfg.datamodule.augmentations,\n",
    "    valid_transforms=cfg.datamodule.valid_transforms,\n",
    "    num_workers=cfg.datamodule.num_workers,\n",
    "    pin_memory=cfg.datamodule.pin_memory,\n",
    "    persistent_workers=cfg.datamodule.persistent_workers,\n",
    "    batch_size=cfg.datamodule.batch_size,\n",
    "    subset_size=0.1,\n",
    ")\n",
    "data_module.setup()\n",
    "# for batch in data_module.train_dataloader():\n",
    "#     x, y = batch\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "len(data_module.train_dataset), len(data_module.val_dataset), len(data_module.test_dataset)\n",
    "# (3600, 900, 500)\n",
    "# (18000, 4500, 2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: tuple[int, int, int],\n",
    "        conv_layers: list[int],\n",
    "        num_classes: int,\n",
    "        dropout_rate: float,\n",
    "        num_hidden_layers: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        input_dim = input_shape[0]\n",
    "        self.output_dims = conv_layers\n",
    "        layers: list[nn.Module] = []\n",
    "        # --- Convolutional layers\n",
    "        for out_dim in conv_layers:\n",
    "            layers.append(nn.Conv2d(input_dim, out_dim, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(out_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = out_dim\n",
    "\n",
    "        self.conv_layers = nn.Sequential(*layers)\n",
    "\n",
    "        # --- To determine the input size for the linear layer\n",
    "        self.flattener = nn.Flatten()\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, *input_shape)\n",
    "            dummy_output = self.conv_layers(dummy_input)\n",
    "            self.flatten_dim = self.flattener(dummy_output).shape[1]\n",
    "        print(f\"Net.__init__() flatten_dim: {self.flatten_dim}\")\n",
    "        # --- Classification head\n",
    "        cls_layers = []\n",
    "        current_fc_input_features = self.flatten_dim\n",
    "        neuron_per_layer = 32\n",
    "        for _ in range(num_hidden_layers):\n",
    "            cls_layers.append(nn.Linear(current_fc_input_features, neuron_per_layer, bias=False))\n",
    "            cls_layers.append(nn.BatchNorm1d(neuron_per_layer))\n",
    "            cls_layers.append(nn.ReLU())\n",
    "            cls_layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "            current_fc_input_features = neuron_per_layer\n",
    "            neuron_per_layer = neuron_per_layer * 2\n",
    "\n",
    "        cls_layers.append(nn.Linear(current_fc_input_features, num_classes))\n",
    "\n",
    "        self.classification_head = nn.Sequential(*cls_layers)\n",
    "        self.model = nn.Sequential(self.conv_layers, self.flattener, self.classification_head)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net.__init__() flatten_dim: 819200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Net                                      [1, 5]                    --\n",
       "├─Sequential: 1-1                        [1, 5]                    --\n",
       "│    └─Sequential: 2-1                   [1, 32, 160, 160]         --\n",
       "│    │    └─Conv2d: 3-1                  [1, 32, 320, 320]         864\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 32, 320, 320]         64\n",
       "│    │    └─ReLU: 3-3                    [1, 32, 320, 320]         --\n",
       "│    │    └─MaxPool2d: 3-4               [1, 32, 160, 160]         --\n",
       "│    │    └─Dropout: 3-5                 [1, 32, 160, 160]         --\n",
       "│    └─Flatten: 2-2                      [1, 819200]               --\n",
       "│    └─Sequential: 2-3                   [1, 5]                    --\n",
       "│    │    └─Linear: 3-6                  [1, 32]                   26,214,400\n",
       "│    │    └─BatchNorm1d: 3-7             [1, 32]                   64\n",
       "│    │    └─ReLU: 3-8                    [1, 32]                   --\n",
       "│    │    └─Dropout: 3-9                 [1, 32]                   --\n",
       "│    │    └─Linear: 3-10                 [1, 64]                   2,048\n",
       "│    │    └─BatchNorm1d: 3-11            [1, 64]                   128\n",
       "│    │    └─ReLU: 3-12                   [1, 64]                   --\n",
       "│    │    └─Dropout: 3-13                [1, 64]                   --\n",
       "│    │    └─Linear: 3-14                 [1, 128]                  8,192\n",
       "│    │    └─BatchNorm1d: 3-15            [1, 128]                  256\n",
       "│    │    └─ReLU: 3-16                   [1, 128]                  --\n",
       "│    │    └─Dropout: 3-17                [1, 128]                  --\n",
       "│    │    └─Linear: 3-18                 [1, 256]                  32,768\n",
       "│    │    └─BatchNorm1d: 3-19            [1, 256]                  512\n",
       "│    │    └─ReLU: 3-20                   [1, 256]                  --\n",
       "│    │    └─Dropout: 3-21                [1, 256]                  --\n",
       "│    │    └─Linear: 3-22                 [1, 5]                    1,285\n",
       "==========================================================================================\n",
       "Total params: 26,260,581\n",
       "Trainable params: 26,260,581\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 114.73\n",
       "==========================================================================================\n",
       "Input size (MB): 1.23\n",
       "Forward/backward pass size (MB): 52.44\n",
       "Params size (MB): 105.04\n",
       "Estimated Total Size (MB): 158.71\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (1, 3, 320, 320)\n",
    "\n",
    "net = Net(\n",
    "    input_shape=input_shape[1:],\n",
    "    conv_layers=[32],\n",
    "    dropout_rate=0.5,\n",
    "    num_classes=len(CLASS_NAMES),\n",
    "    num_hidden_layers=4,\n",
    ")\n",
    "summary(net, input_shape, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-05-08 14:17:29,516]\u001b[0m A new study created in memory with name: no-name-f6b3739f-a1ed-4d5e-b5e0-3a7583f4c532\u001b[0m\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net.__init__() flatten_dim: 307200\n",
      "Using subset of size 0.1 for training, validation, and testing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type               | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | model    | Net                | 9.8 M  | train\n",
      "1 | accuracy | MulticlassAccuracy | 0      | train\n",
      "2 | f1_score | MulticlassF1Score  | 0      | train\n",
      "--------------------------------------------------------\n",
      "9.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.8 M     Total params\n",
      "39.323    Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4294f3e35c3b42e7b7ffdc0b3c972933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b3f0e0fc1f471b89411cc4d4b208c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea3edfc26fc4c2c983af2c9fa38ee03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "\u001b[33m[W 2025-05-08 14:17:43,338]\u001b[0m Trial 0 failed because of the following error: NameError(\"name 'exit' is not defined\")\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py\", line 48, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py\", line 599, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py\", line 1012, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py\", line 1056, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py\", line 216, in run\n",
      "    self.advance()\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py\", line 455, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 150, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 282, in advance\n",
      "    batch, _, __ = next(data_fetcher)\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fetchers.py\", line 134, in __next__\n",
      "    batch = super().__next__()\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fetchers.py\", line 61, in __next__\n",
      "    batch = next(self.iterator)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/combined_loader.py\", line 78, in __next__\n",
      "    out[i] = next(self.iterators[i])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 733, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1491, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1443, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1284, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ultron/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/queue.py\", line 180, in get\n",
      "    self.not_empty.wait(remaining)\n",
      "  File \"/home/ultron/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/threading.py\", line 359, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_158677/1135348939.py\", line 97, in objective\n",
      "    trainer.fit(model, datamodule=datamododule)\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py\", line 561, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/ultron/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py\", line 65, in _call_and_handle_interrupt\n",
      "    exit(1)\n",
      "    ^^^^\n",
      "NameError: name 'exit' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:282\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    281\u001b[39m dataloader_iter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m batch, _, __ = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fetchers.py:134\u001b[39m, in \u001b[36m_PrefetchDataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     batch = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fetchers.py:61\u001b[39m, in \u001b[36m_DataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/combined_loader.py:341\u001b[39m, in \u001b[36mCombinedLoader.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m out = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator, _Sequential):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/combined_loader.py:78\u001b[39m, in \u001b[36m_MaxSizeCycle.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     out[i] = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1443\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m     success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1444\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m success:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1283\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/queue.py:180\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    179\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m item = \u001b[38;5;28mself\u001b[39m._get()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m     gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 107\u001b[39m\n\u001b[32m    105\u001b[39m pruner = optuna.pruners.MedianPruner()\n\u001b[32m    106\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m, pruner=pruner)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/optuna/study/study.py:400\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    392\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_jobs != \u001b[32m1\u001b[39m:\n\u001b[32m    393\u001b[39m     warnings.warn(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis feature will be removed in v4.0.0. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    396\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    397\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    398\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:66\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     79\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m show_progress_bar:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:163\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:264\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    261\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m state == TrialState.FAIL \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch):\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:213\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    210\u001b[39m     thread.start()\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    215\u001b[39m     \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    216\u001b[39m     state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 97\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     95\u001b[39m hyperparameters = \u001b[38;5;28mdict\u001b[39m(conv_layers=conv_channels, hidden_layers=total_cls_hidden_layers, dropout_rate=dropout_rate)\n\u001b[32m     96\u001b[39m trainer.logger.log_hyperparams(hyperparameters)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatamododule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Evaluate the model on the validation set\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# trainer.validate(model, datamodule=datamododule)\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trainer.callback_metrics[\u001b[33m\"\u001b[39m\u001b[33mval_acc\u001b[39m\u001b[33m\"\u001b[39m].item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/practice-projects/CV/lung-and-colon-cancer-classification-pytorch/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "class LungColonClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: Net,\n",
    "        optimizer: torch.optim.Optimizer | None = None,\n",
    "        # scheduler: torch.optim.lr_scheduler.LRScheduler,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "        # self.scheduler = scheduler\n",
    "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=len(CLASS_NAMES))\n",
    "        self.f1_score = F1Score(task=\"multiclass\", num_classes=len(CLASS_NAMES))\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def _common_step(self, batch, batch_idx) -> tuple[torch.Tensor, float, torch.Tensor]:\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss: Tensor = F.cross_entropy(y_hat, y)\n",
    "        score = self.accuracy(y_hat, y)\n",
    "        return loss, score, y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx) -> torch.Tensor:\n",
    "        loss, score, y_hat = self._common_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", score, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx) -> torch.Tensor:\n",
    "        loss, score, y_hat = self._common_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", score, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx) -> torch.Tensor:\n",
    "        loss, score, y_hat = self._common_step(batch, batch_idx)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", score, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer  # (self.model.parameters()), self.scheduler\n",
    "\n",
    "    # return [self.optimizer], [self.scheduler(self.optimizer)]\n",
    "\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    # Define the hyperparameters to optimize\n",
    "    total_conv_layers = trial.suggest_int(\"conv_layers\", 1, 6)\n",
    "    total_cls_hidden_layers = trial.suggest_int(\"hidden_layers\", 1, 6)\n",
    "    conv_channels = [x * 32 for x in range(1, total_conv_layers)]\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "\n",
    "    # Create the model\n",
    "    net = Net(\n",
    "        input_shape=input_shape[1:],\n",
    "        conv_layers=conv_channels,\n",
    "        dropout_rate=dropout_rate,\n",
    "        num_classes=len(CLASS_NAMES),\n",
    "        num_hidden_layers=total_cls_hidden_layers,\n",
    "    )\n",
    "    # # Create the optimizer\n",
    "    # optimizer = torch.optim.AdamW\n",
    "\n",
    "    # Create the scheduler\n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    model = LungColonClassifier(model=net)\n",
    "    datamododule = LungColonDataModule(\n",
    "        train_processed_dir=str(Path(root) / cfg.paths.train_processed_dir),\n",
    "        valid_processed_dir=str(Path(root) / cfg.paths.valid_processed_dir),\n",
    "        test_processed_dir=str(Path(root) / cfg.paths.test_processed_dir),\n",
    "        augmentations=cfg.datamodule.augmentations,\n",
    "        valid_transforms=cfg.datamodule.valid_transforms,\n",
    "        num_workers=cfg.datamodule.num_workers,\n",
    "        pin_memory=cfg.datamodule.pin_memory,\n",
    "        persistent_workers=cfg.datamodule.persistent_workers,\n",
    "        batch_size=cfg.datamodule.batch_size,\n",
    "        subset_size=0.1,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    # callbacks = [PyTorchLightningPruningCallback(trial, monitor=\"val_acc\")]\n",
    "    trainer = pl.Trainer(logger=True, accelerator=\"gpu\", devices=1, max_epochs=10, enable_progress_bar=True, precision=32, log_every_n_steps=1)\n",
    "    hyperparameters = {\"conv_layers\": conv_channels, \"hidden_layers\": total_cls_hidden_layers, \"dropout_rate\": dropout_rate}\n",
    "    trainer.logger.log_hyperparams(hyperparameters)\n",
    "    trainer.fit(model, datamodule=datamododule)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    # trainer.validate(model, datamodule=datamododule)\n",
    "\n",
    "    return trainer.callback_metrics[\"val_acc\"].item()\n",
    "\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "study.optimize(objective, n_trials=100, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "study.optimize(objective, n_trials=5, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
